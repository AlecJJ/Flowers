{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlecJJ/Flowers/blob/main/Alexnet_Flower_sorting_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modules needed for code to function"
      ],
      "metadata": {
        "id": "IwYvzOG5kOAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4CxALkFEElN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Google Drive folders"
      ],
      "metadata": {
        "id": "vBgLun51jDh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# 2. Load labeled images from folders \n",
        "\n",
        "#   Data directory\n",
        "data_dir = '/content/gdrive/MyDrive/Data2023/Flowers'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmZVdOahlb6S",
        "outputId": "5bb9c2c2-261c-4b20-a109-5d33b44853ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing training and valid data"
      ],
      "metadata": {
        "id": "VIw6WmlkjJ6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Pre-process the data and create data loaders\n",
        "# 80% training and 20% valid\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "HN4p4Sv8le3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader"
      ],
      "metadata": {
        "id": "7SmXOMWYjmSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(data_dir + '/' + x, data_transforms[x]) for x in ['train', 'valid']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "g5H3PoNBmHoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588a3612-2136-4d91-96ec-335f6797bfad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fmdxpwxYmhni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alexnet architecture"
      ],
      "metadata": {
        "id": "H-_BgoCrjpWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Set up the AlexNet architecture\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "num_ftrs = alexnet.classifier[6].in_features\n",
        "alexnet.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "alexnet = alexnet.to(device)"
      ],
      "metadata": {
        "id": "L2OhsmMymgGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4406578c-0e05-40bb-d896-c189f910bff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:08<00:00, 27.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alexnet model training"
      ],
      "metadata": {
        "id": "lOSbDOGajucP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 5. Train the AlexNet model\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    for phase in ['train', 'valid']:\n",
        "        if phase == 'train':\n",
        "            alexnet.train()\n",
        "        else:\n",
        "            alexnet.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = alexnet(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    print()\n",
        "\n",
        "print('Training complete')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(alexnet.state_dict(), '/content/gdrive/MyDrive/alexnet_classification.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "sp2GhA5enUhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11a8544-c253-4800-9d02-54cae8a1f212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 2.1253 Acc: 0.1000\n",
            "valid Loss: 1.8349 Acc: 0.4444\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.6151 Acc: 0.3500\n",
            "valid Loss: 1.3645 Acc: 0.6667\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.5713 Acc: 0.4000\n",
            "valid Loss: 1.0048 Acc: 0.8889\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.2131 Acc: 0.6500\n",
            "valid Loss: 0.7649 Acc: 0.8889\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.0486 Acc: 0.7500\n",
            "valid Loss: 0.5766 Acc: 0.8889\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.7762 Acc: 0.8000\n",
            "valid Loss: 0.4445 Acc: 0.8889\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.5303 Acc: 0.9000\n",
            "valid Loss: 0.3497 Acc: 0.8889\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.4131 Acc: 0.9000\n",
            "valid Loss: 0.2759 Acc: 0.8889\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.4507 Acc: 0.8500\n",
            "valid Loss: 0.2067 Acc: 0.8889\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.3296 Acc: 0.9000\n",
            "valid Loss: 0.1500 Acc: 1.0000\n",
            "\n",
            "Training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load trained Alexnet model and predicted results"
      ],
      "metadata": {
        "id": "GKPztW0Aj56p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# 1. Load the trained AlexNet model\n",
        "def load_model(model_path):\n",
        "    model = models.alexnet()\n",
        "    num_ftrs = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_ftrs, len(class_names))\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    return model.to(device)\n",
        "\n",
        "model_path = '/content/gdrive/MyDrive/alexnet_classification.pth'\n",
        "trained_model = load_model(model_path)\n",
        "\n",
        "# 2. Define a function to load an image from a URL and preprocess it\n",
        "def preprocess_image(url, transform):\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    img_tensor = transform(img)\n",
        "    return img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "# 3. Perform inference using the loaded model\n",
        "def predict_image_url(url, model, transform):\n",
        "    img_tensor = preprocess_image(url, transform)\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "    return class_names[pred]\n",
        "\n",
        "image_url = 'https://exploreorca.files.wordpress.com/2018/08/hibiscus-furcellatus4.jpg?w=1126'\n",
        "prediction = predict_image_url(image_url, trained_model, data_transforms['valid'])\n",
        "\n",
        "print(\"The predicted class for the input image is:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWTavdcWFnaU",
        "outputId": "98f962b5-2984-4948-bca7-38a6219307ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted class for the input image is: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ThWclX9Kdas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}